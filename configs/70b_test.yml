model: meta-llama/Llama-3.3-70B-Instruct
use_hf: true

output: outputs/70b_test.jsonl
split: test
B: 1

M: 10
temperature: 0.7
max_new_tokens: 512
