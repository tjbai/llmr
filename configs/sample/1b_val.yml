model: meta-llama/Llama-3.2-1B-Instruct

output: data/1b_validation.jsonl
split: validation
B: 16

M: 1
temperature: 0.7
max_new_tokens: 512
