split: train
model_name: meta-llama/Llama-3.2-1B-Instruct
max_new_tokens: 512
M: 10
temperature: 0.7
output: outputs/small.jsonl
